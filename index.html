<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jeongyun Kim</title>
  
  <meta name="author" content="Jeongyun Kim">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jeongyun Kim</name>
              </p>
              <p> I am Ph.D. student in Mechanical Engineering at the <a href="https://rpm.snu.ac.kr/index.php/Main/About"> RPM Robotics lab</a>, <a href="https://me.snu.ac.kr/en/"> Seoul National University</a>, advised by Prof. <a href="https://ayoungk.github.io/"> Ayoung Kim</a>.
              </p>
              <p></p>
              <p>
                My research interests lie in perception and depth reconstruction for transparent object manipulation, with a particular focus on vision-based neural volumetric synthesis techniques.

              </p>
              <p style="text-align:center">
                <a href="mailto:jeongyunkim@snu.ac.kr">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=vW2JtFAAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/jeongyun0609">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/eongyun-kim-17a2b0349/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/jeongyunkim.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/jeongyunkim.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/TRansPose.gif" alt="TRansPose" width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              TRansPose: Large-scale Multispectral Dataset for Transparent object
            <br>
            <strong>Jeongyun Kim</strong>,
            Myung-Hwan Jeon, Sangwoo Jung, Wooseong Yang, Minwoo Jung, Jaeho Shin and Ayoung Kim
            <br>
            <em>nternational Journal of Robotics Research (IJRR)</em>, 2024
            <br>
            [<a href="https://arxiv.org/abs/2307.05016">arXiv</a>]
            [<a href="https://sites.google.com/view/transpose-dataset/home?authuser=0">dataset site</a>]
            <p></p>
            <p>
              <strong>TRansPose</strong> provides image set obtained from multispectral sensing module such as <strong>RGB, RGB-D</strong> and </strong>TIR</strong>  to enable specialized transparent object recognition.
            </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/transplat.png" alt="Transplat" width="160">
            </td>

            <td style="padding:20px;width:75%;vertical-align:middle">
              TranSplat: Surface Embedding-guided 3D Gaussian Splatting for Transparent Object Manipulation
            </a>
            <br>
            <strong>Jeongyun Kim</strong>,
            Jeongho Noh, DongGuw Lee and Ayoung Kim        
            <br>
            <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2025
            <br>
            [<a href="https://arxiv.org/abs/2502.07840">arXiv</a>]
            [<a href="https://www.youtube.com/watch?v=O_atdUlaF4I">video</a>]
            [<a href="https://github.com/jeongyun0609/TranSplat?tab=readme-ov-file">code</a>]
            <p></p>
            <p>
              TranSplat is a novel framework that leverages latent diffusion‚Äìgenerated surface embeddings to guide 3D Gaussian Splatting, enabling accurate, view-consistent depth completion for transparent objects.
            </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/tranD.png" alt="TranD" width="160">
            </td>

            <td style="padding:20px;width:75%;vertical-align:middle">
              TranD: 2D Gaussian Splatting-based Sparse-view Transparent Object Depth Reconstruction via Physics Simulation for Scene Update
            </a>
            <br>
            <strong>Jeongyun Kim</strong>,
            Seunghoon Jeong, Giseop Kim, Myung-Hwan Jeon, Eunji Jun and Ayoung Kim        
            <br>
            <em>IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2025
            <br>
            Code and arXiv comming soon!
            <!-- [<a href="https://arxiv.org/abs/2502.07840">arXiv</a>]
            [<a href="https://www.youtube.com/watch?v=O_atdUlaF4I">video</a>]
            [<a href="https://github.com/jeongyun0609/TranSplat?tab=readme-ov-file">code</a>] -->
            <p></p>
            <p>
              TranD is a 2D Gaussian Splatting‚Äìbased depth reconstruction method for transparent objects that separates the object from its background and uses an object-aware loss plus a fast physics-based simulation to accurately recover invisible surfaces.
            </p>
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://github.com/jonbarron/jonbarron_website">Template by Jon Barron.</a>
             </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
